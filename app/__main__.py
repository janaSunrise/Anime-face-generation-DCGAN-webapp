import os
import time

import torch
import streamlit as st
from PIL import Image

from . import SAVE_DIR
from .model import discriminator, generator
from .utils import save_samples, get_files_in_dir, generate_video

os.makedirs(SAVE_DIR, exist_ok=True)

# Load and evaluate models
generator.load_state_dict(torch.load("app/models/generator_model.bin", map_location=torch.device('cpu')))
discriminator.load_state_dict(torch.load("app/models/discriminator_model.bin", map_location=torch.device('cpu')))

# Finally, Evaluate them
generator.eval()
discriminator.eval()

# -- Config the warnings -- #
st.set_option('deprecation.showfileUploaderEncoding', False)

# -- The views -- #
st.title("Anime Art generation")
st.header("Anime face image and video generation using Deep Convolutional GANs")

st.header("\n\n")

if __name__ == '__main__':
    option = st.sidebar.selectbox("What do you want to generate?", ("Image", "Video")).lower()

    if option == "video":
        video_range = st.sidebar.slider("How many video frames?", 3, 30, 5)

    if st.sidebar.button("Click here to generate!"):
        with st.spinner("Generating..."):
            if option == "image":
                save_samples(generator)
                filename = get_files_in_dir(SAVE_DIR)[0]
            else:
                for idx in range(video_range):
                    save_samples(generator, idx)

            time.sleep(1)

            st.success("Generation done!")
            st.balloons()

            if option == "image":
                image = Image.open(filename)
                st.image(image, caption="Anime generated by DCGAN")
            else:
                vid_filename = "anime_timelapse.webm"
                generate_video(SAVE_DIR, vid_filename)

                video_file = open(vid_filename, 'rb')
                video_bytes = video_file.read()
                st.video(video_bytes)
